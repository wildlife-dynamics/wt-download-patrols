# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details


# ruff: noqa: E402

# %% [markdown]
# # Download Patrols
# TODO: top level description

# %% [markdown]
# ## Imports

import os

from ecoscope_workflows_core.tasks.config import set_string_var as set_string_var
from ecoscope_workflows_core.tasks.config import (
    set_workflow_details as set_workflow_details,
)
from ecoscope_workflows_core.tasks.filter import (
    get_timezone_from_time_range as get_timezone_from_time_range,
)
from ecoscope_workflows_core.tasks.filter import set_time_range as set_time_range
from ecoscope_workflows_core.tasks.groupby import groupbykey as groupbykey
from ecoscope_workflows_core.tasks.groupby import set_groupers as set_groupers
from ecoscope_workflows_core.tasks.groupby import split_groups as split_groups
from ecoscope_workflows_core.tasks.io import persist_text as persist_text
from ecoscope_workflows_core.tasks.io import set_er_connection as set_er_connection
from ecoscope_workflows_core.tasks.results import (
    create_map_widget_single_view as create_map_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import gather_dashboard as gather_dashboard
from ecoscope_workflows_core.tasks.results import (
    merge_widget_views as merge_widget_views,
)
from ecoscope_workflows_core.tasks.skip import (
    all_keyed_iterables_are_skips as all_keyed_iterables_are_skips,
)
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_skipped as any_dependency_skipped,
)
from ecoscope_workflows_core.tasks.skip import any_is_empty_df as any_is_empty_df
from ecoscope_workflows_core.tasks.skip import never as never
from ecoscope_workflows_core.tasks.transformation import (
    add_temporal_index as add_temporal_index,
)
from ecoscope_workflows_core.tasks.transformation import (
    convert_column_values_to_string as convert_column_values_to_string,
)
from ecoscope_workflows_core.tasks.transformation import (
    convert_values_to_timezone as convert_values_to_timezone,
)
from ecoscope_workflows_core.tasks.transformation import map_columns as map_columns
from ecoscope_workflows_ext_custom.tasks.io import (
    persist_df_wrapper as persist_df_wrapper,
)
from ecoscope_workflows_ext_custom.tasks.skip import maybe_skip_df as maybe_skip_df
from ecoscope_workflows_ext_custom.tasks.transformation import (
    apply_sql_query as apply_sql_query,
)
from ecoscope_workflows_ext_custom.tasks.transformation import (
    drop_column_prefix as drop_column_prefix,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_event_type_display_names_from_events as get_event_type_display_names_from_events,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_patrol_observations_from_patrols_df_and_combined_params as get_patrol_observations_from_patrols_df_and_combined_params,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_patrols_from_combined_params as get_patrols_from_combined_params,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    set_patrols_and_patrol_events_params as set_patrols_and_patrol_events_params,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    unpack_events_from_patrols_df_and_combined_params as unpack_events_from_patrols_df_and_combined_params,
)
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    relocations_to_trajectory as relocations_to_trajectory,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_point_layer as create_point_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_polyline_layer as create_polyline_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import draw_ecomap as draw_ecomap
from ecoscope_workflows_ext_ecoscope.tasks.results import set_base_maps as set_base_maps
from ecoscope_workflows_ext_ecoscope.tasks.skip import (
    all_geometry_are_none as all_geometry_are_none,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_color_map as apply_color_map,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_reloc_coord_filter as apply_reloc_coord_filter,
)

# %% [markdown]
# ## Workflow Details

# %%
# parameters

workflow_details_params = dict(
    name=...,
    description=...,
    image_url=...,
)

# %%
# call the task


workflow_details = (
    set_workflow_details.set_task_instance_id("workflow_details")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**workflow_details_params)
    .call()
)


# %% [markdown]
# ## Data Source

# %%
# parameters

er_client_name_params = dict(
    data_source=...,
)

# %%
# call the task


er_client_name = (
    set_er_connection.set_task_instance_id("er_client_name")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**er_client_name_params)
    .call()
)


# %% [markdown]
# ## Time Range

# %%
# parameters

time_range_params = dict(
    since=...,
    until=...,
    timezone=...,
)

# %%
# call the task


time_range = (
    set_time_range.set_task_instance_id("time_range")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(time_format="%d %b %Y %H:%M:%S %Z", **time_range_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

er_patrol_and_events_params_params = dict(
    patrol_types=...,
    event_types=...,
    status=...,
    include_null_geometry=...,
)

# %%
# call the task


er_patrol_and_events_params = (
    set_patrols_and_patrol_events_params.set_task_instance_id(
        "er_patrol_and_events_params"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        time_range=time_range,
        include_patrol_details=True,
        raise_on_empty=False,
        truncate_to_time_range=True,
        sub_page_size=100,
        **er_patrol_and_events_params_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

prefetch_patrols_params = dict()

# %%
# call the task


prefetch_patrols = (
    get_patrols_from_combined_params.set_task_instance_id("prefetch_patrols")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(combined_params=er_patrol_and_events_params, **prefetch_patrols_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

patrol_obs_params = dict()

# %%
# call the task


patrol_obs = (
    get_patrol_observations_from_patrols_df_and_combined_params.set_task_instance_id(
        "patrol_obs"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        patrols_df=prefetch_patrols,
        combined_params=er_patrol_and_events_params,
        **patrol_obs_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

patrol_events_params = dict()

# %%
# call the task


patrol_events = (
    unpack_events_from_patrols_df_and_combined_params.set_task_instance_id(
        "patrol_events"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        patrols_df=prefetch_patrols,
        combined_params=er_patrol_and_events_params,
        **patrol_events_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

event_type_display_names_params = dict()

# %%
# call the task


event_type_display_names = (
    get_event_type_display_names_from_events.set_task_instance_id(
        "event_type_display_names"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        events_gdf=patrol_events,
        append_category_names="duplicates",
        **event_type_display_names_params,
    )
    .call()
)


# %% [markdown]
# ## Extract Timezone Selection

# %%
# parameters

get_timezone_params = dict()

# %%
# call the task


get_timezone = (
    get_timezone_from_time_range.set_task_instance_id("get_timezone")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(time_range=time_range, **get_timezone_params)
    .call()
)


# %% [markdown]
# ## Convert Patrol Observations to Timezone

# %%
# parameters

convert_patrols_to_user_timezone_params = dict()

# %%
# call the task


convert_patrols_to_user_timezone = (
    convert_values_to_timezone.set_task_instance_id("convert_patrols_to_user_timezone")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=patrol_obs,
        timezone=get_timezone,
        columns=["fixtime"],
        **convert_patrols_to_user_timezone_params,
    )
    .call()
)


# %% [markdown]
# ## Convert Patrol Events to Timezone

# %%
# parameters

convert_events_to_user_timezone_params = dict()

# %%
# call the task


convert_events_to_user_timezone = (
    convert_values_to_timezone.set_task_instance_id("convert_events_to_user_timezone")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=patrol_events,
        timezone=get_timezone,
        columns=["time"],
        **convert_events_to_user_timezone_params,
    )
    .call()
)


# %% [markdown]
# ## Remove Column Prefix Extra

# %%
# parameters

drop_extra_prefix_obs_params = dict()

# %%
# call the task


drop_extra_prefix_obs = (
    drop_column_prefix.set_task_instance_id("drop_extra_prefix_obs")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=convert_patrols_to_user_timezone,
        prefix="extra__",
        duplicate_strategy="suffix",
        **drop_extra_prefix_obs_params,
    )
    .call()
)


# %% [markdown]
# ## Filter Observation Relocations

# %%
# parameters

filter_patrol_obs_params = dict()

# %%
# call the task


filter_patrol_obs = (
    apply_reloc_coord_filter.set_task_instance_id("filter_patrol_obs")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=drop_extra_prefix_obs,
        roi_gdf=None,
        roi_name=None,
        reset_index=False,
        bounding_box={"min_x": -180.0, "max_x": 180.0, "min_y": -90.0, "max_y": 90.0},
        filter_point_coords=[
            {"x": 180.0, "y": 90.0},
            {"x": 0.0, "y": 0.0},
            {"x": 1.0, "y": 1.0},
        ],
        **filter_patrol_obs_params,
    )
    .call()
)


# %% [markdown]
# ## Trajectory Segment Filter

# %%
# parameters

patrol_traj_params = dict(
    trajectory_segment_filter=...,
)

# %%
# call the task


patrol_traj = (
    relocations_to_trajectory.set_task_instance_id("patrol_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(relocations=filter_patrol_obs, **patrol_traj_params)
    .call()
)


# %% [markdown]
# ## Remove Column Prefix Extra

# %%
# parameters

drop_extra_prefix_traj_params = dict()

# %%
# call the task


drop_extra_prefix_traj = (
    drop_column_prefix.set_task_instance_id("drop_extra_prefix_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=patrol_traj,
        prefix="extra__",
        duplicate_strategy="suffix",
        **drop_extra_prefix_traj_params,
    )
    .call()
)


# %% [markdown]
# ## Internally Process Columns

# %%
# parameters

customize_columns_internally_params = dict()

# %%
# call the task


customize_columns_internally = (
    map_columns.set_task_instance_id("customize_columns_internally")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=drop_extra_prefix_traj,
        rename_columns={},
        drop_columns=["id"],
        retain_columns=[],
        **customize_columns_internally_params,
    )
    .call()
)


# %% [markdown]
# ## Process Columns

# %%
# parameters

customize_columns_traj_params = dict(
    drop_columns=...,
)

# %%
# call the task


customize_columns_traj = (
    map_columns.set_task_instance_id("customize_columns_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=customize_columns_internally,
        rename_columns={},
        retain_columns=[],
        **customize_columns_traj_params,
    )
    .call()
)


# %% [markdown]
# ## Apply SQL Query

# %%
# parameters

sql_query_traj_params = dict(
    query=...,
    columns=...,
)

# %%
# call the task


sql_query_traj = (
    apply_sql_query.set_task_instance_id("sql_query_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(df=customize_columns_traj, **sql_query_traj_params)
    .call()
)


# %% [markdown]
# ## Group Data

# %%
# parameters

groupers_params = dict(
    groupers=...,
)

# %%
# call the task


groupers = (
    set_groupers.set_task_instance_id("groupers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**groupers_params)
    .call()
)


# %% [markdown]
# ## Style Trajectory By Category

# %%
# parameters

set_patrol_traj_color_column_params = dict(
    var=...,
)

# %%
# call the task


set_patrol_traj_color_column = (
    set_string_var.set_task_instance_id("set_patrol_traj_color_column")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**set_patrol_traj_color_column_params)
    .call()
)


# %% [markdown]
# ## Add temporal index to Patrol Trajectories

# %%
# parameters

traj_add_temporal_index_params = dict()

# %%
# call the task


traj_add_temporal_index = (
    add_temporal_index.set_task_instance_id("traj_add_temporal_index")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=sql_query_traj,
        time_col="segment_start",
        groupers=groupers,
        cast_to_datetime=True,
        format="mixed",
        **traj_add_temporal_index_params,
    )
    .call()
)


# %% [markdown]
# ## Rename value grouper columns for Trajectories

# %%
# parameters

traj_rename_grouper_columns_params = dict()

# %%
# call the task


traj_rename_grouper_columns = (
    map_columns.set_task_instance_id("traj_rename_grouper_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=traj_add_temporal_index,
        drop_columns=["patrol_type"],
        retain_columns=[],
        rename_columns={"patrol_type__value": "patrol_type"},
        **traj_rename_grouper_columns_params,
    )
    .call()
)


# %% [markdown]
# ## Patrol Traj Colormap

# %%
# parameters

traj_colormap_params = dict()

# %%
# call the task


traj_colormap = (
    apply_color_map.set_task_instance_id("traj_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=traj_rename_grouper_columns,
        colormap=[
            "#FF9600",
            "#F23B0E",
            "#A100CB",
            "#F04564",
            "#03421A",
            "#3089FF",
            "#E26FFF",
            "#8C1700",
            "#002960",
            "#FFD000",
            "#B62879",
            "#680078",
            "#005A56",
            "#0056C7",
            "#331878",
            "#E76826",
        ],
        input_column_name=set_patrol_traj_color_column,
        output_column_name="patrol_traj_colormap",
        **traj_colormap_params,
    )
    .call()
)


# %% [markdown]
# ## Remove Column Prefix Extra

# %%
# parameters

drop_extra_prefix_events_params = dict()

# %%
# call the task


drop_extra_prefix_events = (
    drop_column_prefix.set_task_instance_id("drop_extra_prefix_events")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=convert_events_to_user_timezone,
        prefix="extra__",
        duplicate_strategy="suffix",
        **drop_extra_prefix_events_params,
    )
    .call()
)


# %% [markdown]
# ## Apply Coordinate Filter to Patrol Events

# %%
# parameters

filter_patrol_events_params = dict(
    bounding_box=...,
    filter_point_coords=...,
)

# %%
# call the task


filter_patrol_events = (
    apply_reloc_coord_filter.set_task_instance_id("filter_patrol_events")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=drop_extra_prefix_events,
        roi_gdf=None,
        roi_name=None,
        reset_index=True,
        **filter_patrol_events_params,
    )
    .call()
)


# %% [markdown]
# ## Add temporal index to Patrol Events

# %%
# parameters

pe_add_temporal_index_params = dict()

# %%
# call the task


pe_add_temporal_index = (
    add_temporal_index.set_task_instance_id("pe_add_temporal_index")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=filter_patrol_events,
        time_col="patrol_start_time",
        groupers=groupers,
        cast_to_datetime=True,
        format="mixed",
        **pe_add_temporal_index_params,
    )
    .call()
)


# %% [markdown]
# ## Patrol Events Colormap

# %%
# parameters

pe_colormap_params = dict()

# %%
# call the task


pe_colormap = (
    apply_color_map.set_task_instance_id("pe_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=pe_add_temporal_index,
        input_column_name="event_type",
        colormap="tab20b",
        output_column_name="event_type_colormap",
        **pe_colormap_params,
    )
    .call()
)


# %% [markdown]
# ## Cast Patrol Trajectory Columns

# %%
# parameters

patrol_traj_cols_to_string_params = dict()

# %%
# call the task


patrol_traj_cols_to_string = (
    convert_column_values_to_string.set_task_instance_id("patrol_traj_cols_to_string")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=traj_colormap,
        columns=["patrol_serial_number", "patrol_type"],
        **patrol_traj_cols_to_string_params,
    )
    .call()
)


# %% [markdown]
# ## Cast Patrol Events Columns

# %%
# parameters

pe_cols_to_string_params = dict()

# %%
# call the task


pe_cols_to_string = (
    convert_column_values_to_string.set_task_instance_id("pe_cols_to_string")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=pe_colormap,
        columns=["patrol_serial_number", "patrol_type"],
        **pe_cols_to_string_params,
    )
    .call()
)


# %% [markdown]
# ## Split Patrol Trajectories by Group

# %%
# parameters

split_patrol_traj_groups_params = dict()

# %%
# call the task


split_patrol_traj_groups = (
    split_groups.set_task_instance_id("split_patrol_traj_groups")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(df=traj_colormap, groupers=groupers, **split_patrol_traj_groups_params)
    .call()
)


# %% [markdown]
# ## Split Patrol Events by Group

# %%
# parameters

split_pe_groups_params = dict()

# %%
# call the task


split_pe_groups = (
    split_groups.set_task_instance_id("split_pe_groups")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(df=pe_colormap, groupers=groupers, **split_pe_groups_params)
    .call()
)


# %% [markdown]
# ## Persist Patrol Trajectories

# %%
# parameters

persist_patrol_traj_params = dict(
    filename=...,
    filetypes=...,
    filename_prefix=...,
)

# %%
# call the task


persist_patrol_traj = (
    persist_df_wrapper.set_task_instance_id("persist_patrol_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        sanitize=True,
        **persist_patrol_traj_params,
    )
    .mapvalues(argnames=["df"], argvalues=split_patrol_traj_groups)
)


# %% [markdown]
# ## Persist Patrol Events

# %%
# parameters

persist_patrol_events_params = dict(
    filename=...,
    filetypes=...,
    filename_prefix=...,
)

# %%
# call the task


persist_patrol_events = (
    persist_df_wrapper.set_task_instance_id("persist_patrol_events")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        sanitize=True,
        **persist_patrol_events_params,
    )
    .mapvalues(argnames=["df"], argvalues=split_pe_groups)
)


# %% [markdown]
# ## Skip Map Generation

# %%
# parameters

skip_map_generation_params = dict(
    skip=...,
)

# %%
# call the task


skip_map_generation = (
    maybe_skip_df.set_task_instance_id("skip_map_generation")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**skip_map_generation_params)
    .mapvalues(argnames=["df"], argvalues=split_patrol_traj_groups)
)


# %% [markdown]
# ## Set Patrol Map Title

# %%
# parameters

set_patrol_map_title_params = dict()

# %%
# call the task


set_patrol_map_title = (
    set_string_var.set_task_instance_id("set_patrol_map_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var="Patrol Trajectories and Events Map", **set_patrol_map_title_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

base_map_defs_params = dict(
    base_maps=...,
)

# %%
# call the task


base_map_defs = (
    set_base_maps.set_task_instance_id("base_map_defs")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**base_map_defs_params)
    .call()
)


# %% [markdown]
# ## Rename Trajectory Columns for Display

# %%
# parameters

rename_traj_display_columns_params = dict()

# %%
# call the task


rename_traj_display_columns = (
    map_columns.set_task_instance_id("rename_traj_display_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        drop_columns=[],
        retain_columns=[],
        rename_columns={
            "patrol_serial_number": "Patrol Serial",
            "patrol_type__display": "Patrol Type",
            "segment_start": "Start Time",
            "timespan_seconds": "Duration (s)",
            "speed_kmhr": "Speed (kph)",
        },
        **rename_traj_display_columns_params,
    )
    .mapvalues(argnames=["df"], argvalues=skip_map_generation)
)


# %% [markdown]
# ## Rename Event Columns for Display

# %%
# parameters

rename_event_display_columns_params = dict()

# %%
# call the task


rename_event_display_columns = (
    map_columns.set_task_instance_id("rename_event_display_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        drop_columns=[],
        retain_columns=[],
        rename_columns={
            "patrol_serial_number": "Patrol Serial",
            "event_type": "Event Type",
            "time": "Event Time",
        },
        **rename_event_display_columns_params,
    )
    .mapvalues(argnames=["df"], argvalues=split_pe_groups)
)


# %% [markdown]
# ## Create Trajectory Map Layers

# %%
# parameters

patrol_traj_map_layers_params = dict(
    zoom=...,
)

# %%
# call the task


patrol_traj_map_layers = (
    create_polyline_layer.set_task_instance_id("patrol_traj_map_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={
            "get_width": 3,
            "width_units": "pixels",
            "color_column": "patrol_traj_colormap",
        },
        legend={
            "label_column": set_patrol_traj_color_column,
            "color_column": "patrol_traj_colormap",
        },
        tooltip_columns=[
            "Patrol Serial",
            "Patrol Type",
            "Start Time",
            "Duration (s)",
            "Speed (kph)",
        ],
        **patrol_traj_map_layers_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=rename_traj_display_columns)
)


# %% [markdown]
# ## Create Event Map Layers

# %%
# parameters

patrol_events_map_layers_params = dict(
    zoom=...,
)

# %%
# call the task


patrol_events_map_layers = (
    create_point_layer.set_task_instance_id("patrol_events_map_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={"fill_color_column": "event_type_colormap", "get_radius": 5},
        legend=None,
        tooltip_columns=["Patrol Serial", "Event Type", "Event Time"],
        **patrol_events_map_layers_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=rename_event_display_columns)
)


# %% [markdown]
# ## Combine Trajectories and Patrol Events Layers

# %%
# parameters

combined_traj_and_pe_map_layers_params = dict()

# %%
# call the task


combined_traj_and_pe_map_layers = (
    groupbykey.set_task_instance_id("combined_traj_and_pe_map_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            all_keyed_iterables_are_skips,
        ],
        unpack_depth=1,
    )
    .partial(
        iterables=[patrol_traj_map_layers, patrol_events_map_layers],
        **combined_traj_and_pe_map_layers_params,
    )
    .call()
)


# %% [markdown]
# ## Draw Ecomaps

# %%
# parameters

traj_patrol_events_ecomap_params = dict(
    view_state=...,
)

# %%
# call the task


traj_patrol_events_ecomap = (
    draw_ecomap.set_task_instance_id("traj_patrol_events_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        title=None,
        tile_layers=base_map_defs,
        north_arrow_style={"placement": "top-left"},
        legend_style={
            "title": set_patrol_traj_color_column,
            "format_title": True,
            "placement": "bottom-right",
        },
        static=False,
        max_zoom=20,
        widget_id=set_patrol_map_title,
        **traj_patrol_events_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers"], argvalues=combined_traj_and_pe_map_layers)
)


# %% [markdown]
# ## Persist Ecomaps

# %%
# parameters

traj_pe_ecomap_html_urls_params = dict(
    filename=...,
    filename_suffix=...,
)

# %%
# call the task


traj_pe_ecomap_html_urls = (
    persist_text.set_task_instance_id("traj_pe_ecomap_html_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        **traj_pe_ecomap_html_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=traj_patrol_events_ecomap)
)


# %% [markdown]
# ## Create Ecomap Widgets

# %%
# parameters

traj_pe_map_widgets_single_views_params = dict()

# %%
# call the task


traj_pe_map_widgets_single_views = (
    create_map_widget_single_view.set_task_instance_id(
        "traj_pe_map_widgets_single_views"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_patrol_map_title, **traj_pe_map_widgets_single_views_params)
    .map(argnames=["view", "data"], argvalues=traj_pe_ecomap_html_urls)
)


# %% [markdown]
# ## Merge Ecomap Views

# %%
# parameters

traj_pe_grouped_map_widget_params = dict()

# %%
# call the task


traj_pe_grouped_map_widget = (
    merge_widget_views.set_task_instance_id("traj_pe_grouped_map_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        widgets=traj_pe_map_widgets_single_views, **traj_pe_grouped_map_widget_params
    )
    .call()
)


# %% [markdown]
# ## Create Dashboard with Patrol Map Widgets

# %%
# parameters

patrol_dashboard_params = dict(
    warning=...,
)

# %%
# call the task


patrol_dashboard = (
    gather_dashboard.set_task_instance_id("patrol_dashboard")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        details=workflow_details,
        widgets=[traj_pe_grouped_map_widget],
        groupers=groupers,
        time_range=time_range,
        **patrol_dashboard_params,
    )
    .call()
)

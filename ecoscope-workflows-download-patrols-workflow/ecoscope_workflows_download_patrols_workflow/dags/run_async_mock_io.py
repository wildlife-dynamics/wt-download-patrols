# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details

# ruff: noqa: E402

"""WARNING: This file is generated in a testing context and should not be used in production.
Lines specific to the testing context are marked with a test tube emoji (ðŸ§ª) to indicate
that they would not be included (or would be different) in the production version of this file.
"""

import json
import os
import warnings  # ðŸ§ª

from ecoscope_workflows_core.graph import DependsOn, Graph, Node
from ecoscope_workflows_core.tasks.config import (
    set_workflow_details as set_workflow_details,
)
from ecoscope_workflows_core.tasks.filter import set_time_range as set_time_range
from ecoscope_workflows_core.tasks.io import set_er_connection as set_er_connection
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_skipped as any_dependency_skipped,
)
from ecoscope_workflows_core.tasks.skip import any_is_empty_df as any_is_empty_df
from ecoscope_workflows_core.testing import create_task_magicmock  # ðŸ§ª
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    set_patrol_status as set_patrol_status,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    set_patrol_types as set_patrol_types,
)

get_patrol_observations = create_task_magicmock(  # ðŸ§ª
    anchor="ecoscope_workflows_ext_ecoscope.tasks.io",  # ðŸ§ª
    func_name="get_patrol_observations",  # ðŸ§ª
)  # ðŸ§ª

get_patrol_events = create_task_magicmock(  # ðŸ§ª
    anchor="ecoscope_workflows_ext_ecoscope.tasks.io",  # ðŸ§ª
    func_name="get_patrol_events",  # ðŸ§ª
)  # ðŸ§ª
from ecoscope_workflows_core.tasks.config import set_string_var as set_string_var
from ecoscope_workflows_core.tasks.groupby import groupbykey as groupbykey
from ecoscope_workflows_core.tasks.groupby import set_groupers as set_groupers
from ecoscope_workflows_core.tasks.groupby import split_groups as split_groups
from ecoscope_workflows_core.tasks.io import persist_text as persist_text
from ecoscope_workflows_core.tasks.results import (
    create_map_widget_single_view as create_map_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import gather_dashboard as gather_dashboard
from ecoscope_workflows_core.tasks.results import (
    merge_widget_views as merge_widget_views,
)
from ecoscope_workflows_core.tasks.skip import (
    all_keyed_iterables_are_skips as all_keyed_iterables_are_skips,
)
from ecoscope_workflows_core.tasks.transformation import (
    add_temporal_index as add_temporal_index,
)
from ecoscope_workflows_core.tasks.transformation import (
    convert_column_values_to_string as convert_column_values_to_string,
)
from ecoscope_workflows_core.tasks.transformation import map_columns as map_columns
from ecoscope_workflows_ext_ecoscope.tasks.io import persist_df as persist_df
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    process_relocations as process_relocations,
)
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    relocations_to_trajectory as relocations_to_trajectory,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_point_layer as create_point_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_polyline_layer as create_polyline_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import draw_ecomap as draw_ecomap
from ecoscope_workflows_ext_ecoscope.tasks.results import set_base_maps as set_base_maps
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_color_map as apply_color_map,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_reloc_coord_filter as apply_reloc_coord_filter,
)

from ..params import Params


def main(params: Params):
    warnings.warn("This test script should not be used in production!")  # ðŸ§ª

    params_dict = json.loads(params.model_dump_json(exclude_unset=True))

    dependencies = {
        "workflow_details": [],
        "er_client_name": [],
        "time_range": [],
        "er_patrol_types": [],
        "er_patrol_status": [],
        "patrol_obs": [
            "er_client_name",
            "time_range",
            "er_patrol_types",
            "er_patrol_status",
        ],
        "fetch_patrol_events": [
            "er_client_name",
            "time_range",
            "er_patrol_types",
            "er_patrol_status",
        ],
        "groupers": [],
        "patrol_reloc": ["patrol_obs"],
        "set_patrol_traj_color_column": [],
        "patrol_traj": ["patrol_reloc"],
        "traj_add_temporal_index": ["patrol_traj", "groupers"],
        "traj_rename_grouper_columns": ["traj_add_temporal_index"],
        "traj_colormap": [
            "traj_rename_grouper_columns",
            "set_patrol_traj_color_column",
        ],
        "filter_fetched_patrol_events": ["fetch_patrol_events"],
        "pe_add_temporal_index": ["filter_fetched_patrol_events", "groupers"],
        "pe_colormap": ["pe_add_temporal_index"],
        "patrol_traj_cols_to_string": ["traj_colormap"],
        "pe_cols_to_string": ["pe_colormap"],
        "filter_patrol_events": ["fetch_patrol_events"],
        "split_patrol_traj_groups": ["traj_colormap", "groupers"],
        "split_pe_groups": ["pe_colormap", "groupers"],
        "persist_traj_gpkg": ["patrol_traj"],
        "persist_traj_parquet": ["patrol_traj"],
        "persist_events_gpkg": ["filter_patrol_events"],
        "persist_events_parquet": ["filter_patrol_events"],
        "base_map_defs": [],
        "patrol_events_map_layers": ["split_pe_groups"],
        "patrol_traj_map_layers": ["split_patrol_traj_groups"],
        "combined_traj_and_pe_map_layers": [
            "patrol_traj_map_layers",
            "patrol_events_map_layers",
        ],
        "traj_patrol_events_ecomap": [
            "base_map_defs",
            "combined_traj_and_pe_map_layers",
        ],
        "traj_pe_ecomap_html_urls": ["traj_patrol_events_ecomap"],
        "traj_pe_map_widgets_single_views": ["traj_pe_ecomap_html_urls"],
        "traj_pe_grouped_map_widget": ["traj_pe_map_widgets_single_views"],
        "patrol_dashboard": [
            "workflow_details",
            "traj_pe_grouped_map_widget",
            "groupers",
            "time_range",
        ],
    }

    nodes = {
        "workflow_details": Node(
            async_task=set_workflow_details.validate()
            .set_task_instance_id("workflow_details")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("workflow_details") or {}),
            method="call",
        ),
        "er_client_name": Node(
            async_task=set_er_connection.validate()
            .set_task_instance_id("er_client_name")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("er_client_name") or {}),
            method="call",
        ),
        "time_range": Node(
            async_task=set_time_range.validate()
            .set_task_instance_id("time_range")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "time_format": "%d %b %Y %H:%M:%S %Z",
            }
            | (params_dict.get("time_range") or {}),
            method="call",
        ),
        "er_patrol_types": Node(
            async_task=set_patrol_types.validate()
            .set_task_instance_id("er_patrol_types")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("er_patrol_types") or {}),
            method="call",
        ),
        "er_patrol_status": Node(
            async_task=set_patrol_status.validate()
            .set_task_instance_id("er_patrol_status")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("er_patrol_status") or {}),
            method="call",
        ),
        "patrol_obs": Node(
            async_task=get_patrol_observations.validate()
            .set_task_instance_id("patrol_obs")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "client": DependsOn("er_client_name"),
                "time_range": DependsOn("time_range"),
                "patrol_types": DependsOn("er_patrol_types"),
                "status": DependsOn("er_patrol_status"),
                "include_patrol_details": True,
                "raise_on_empty": False,
            }
            | (params_dict.get("patrol_obs") or {}),
            method="call",
        ),
        "fetch_patrol_events": Node(
            async_task=get_patrol_events.validate()
            .set_task_instance_id("fetch_patrol_events")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "client": DependsOn("er_client_name"),
                "time_range": DependsOn("time_range"),
                "patrol_types": DependsOn("er_patrol_types"),
                "status": DependsOn("er_patrol_status"),
                "truncate_to_time_range": True,
                "raise_on_empty": False,
            }
            | (params_dict.get("fetch_patrol_events") or {}),
            method="call",
        ),
        "groupers": Node(
            async_task=set_groupers.validate()
            .set_task_instance_id("groupers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("groupers") or {}),
            method="call",
        ),
        "patrol_reloc": Node(
            async_task=process_relocations.validate()
            .set_task_instance_id("patrol_reloc")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "observations": DependsOn("patrol_obs"),
                "relocs_columns": [
                    "patrol_id",
                    "patrol_start_time",
                    "patrol_end_time",
                    "patrol_type__value",
                    "patrol_type__display",
                    "patrol_serial_number",
                    "patrol_status",
                    "patrol_subject",
                    "groupby_col",
                    "fixtime",
                    "junk_status",
                    "extra__source",
                    "geometry",
                ],
                "filter_point_coords": [
                    {
                        "x": 180.0,
                        "y": 90.0,
                    },
                    {
                        "x": 0.0,
                        "y": 0.0,
                    },
                    {
                        "x": 1.0,
                        "y": 1.0,
                    },
                ],
            }
            | (params_dict.get("patrol_reloc") or {}),
            method="call",
        ),
        "set_patrol_traj_color_column": Node(
            async_task=set_string_var.validate()
            .set_task_instance_id("set_patrol_traj_color_column")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "var": "patrol_type",
            }
            | (params_dict.get("set_patrol_traj_color_column") or {}),
            method="call",
        ),
        "patrol_traj": Node(
            async_task=relocations_to_trajectory.validate()
            .set_task_instance_id("patrol_traj")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "relocations": DependsOn("patrol_reloc"),
            }
            | (params_dict.get("patrol_traj") or {}),
            method="call",
        ),
        "traj_add_temporal_index": Node(
            async_task=add_temporal_index.validate()
            .set_task_instance_id("traj_add_temporal_index")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("patrol_traj"),
                "time_col": "extra__patrol_start_time",
                "groupers": DependsOn("groupers"),
                "cast_to_datetime": True,
                "format": "mixed",
            }
            | (params_dict.get("traj_add_temporal_index") or {}),
            method="call",
        ),
        "traj_rename_grouper_columns": Node(
            async_task=map_columns.validate()
            .set_task_instance_id("traj_rename_grouper_columns")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("traj_add_temporal_index"),
                "rename_columns": {
                    "extra__patrol_type__value": "patrol_type",
                    "extra__patrol_serial_number": "patrol_serial_number",
                    "extra__patrol_status": "patrol_status",
                    "extra__patrol_subject": "patrol_subject",
                },
            }
            | (params_dict.get("traj_rename_grouper_columns") or {}),
            method="call",
        ),
        "traj_colormap": Node(
            async_task=apply_color_map.validate()
            .set_task_instance_id("traj_colormap")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("traj_rename_grouper_columns"),
                "colormap": [
                    "#FF9600",
                    "#F23B0E",
                    "#A100CB",
                    "#F04564",
                    "#03421A",
                    "#3089FF",
                    "#E26FFF",
                    "#8C1700",
                    "#002960",
                    "#FFD000",
                    "#B62879",
                    "#680078",
                    "#005A56",
                    "#0056C7",
                    "#331878",
                    "#E76826",
                ],
                "input_column_name": DependsOn("set_patrol_traj_color_column"),
                "output_column_name": "patrol_traj_colormap",
            }
            | (params_dict.get("traj_colormap") or {}),
            method="call",
        ),
        "filter_fetched_patrol_events": Node(
            async_task=apply_reloc_coord_filter.validate()
            .set_task_instance_id("filter_fetched_patrol_events")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("fetch_patrol_events"),
                "roi_gdf": None,
                "roi_name": None,
            }
            | (params_dict.get("filter_fetched_patrol_events") or {}),
            method="call",
        ),
        "pe_add_temporal_index": Node(
            async_task=add_temporal_index.validate()
            .set_task_instance_id("pe_add_temporal_index")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("filter_fetched_patrol_events"),
                "time_col": "patrol_start_time",
                "groupers": DependsOn("groupers"),
                "cast_to_datetime": True,
                "format": "mixed",
            }
            | (params_dict.get("pe_add_temporal_index") or {}),
            method="call",
        ),
        "pe_colormap": Node(
            async_task=apply_color_map.validate()
            .set_task_instance_id("pe_colormap")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("pe_add_temporal_index"),
                "input_column_name": "event_type",
                "colormap": "tab20b",
                "output_column_name": "event_type_colormap",
            }
            | (params_dict.get("pe_colormap") or {}),
            method="call",
        ),
        "patrol_traj_cols_to_string": Node(
            async_task=convert_column_values_to_string.validate()
            .set_task_instance_id("patrol_traj_cols_to_string")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("traj_colormap"),
                "columns": [
                    "patrol_serial_number",
                    "patrol_type",
                ],
            }
            | (params_dict.get("patrol_traj_cols_to_string") or {}),
            method="call",
        ),
        "pe_cols_to_string": Node(
            async_task=convert_column_values_to_string.validate()
            .set_task_instance_id("pe_cols_to_string")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("pe_colormap"),
                "columns": [
                    "patrol_serial_number",
                    "patrol_type",
                ],
            }
            | (params_dict.get("pe_cols_to_string") or {}),
            method="call",
        ),
        "filter_patrol_events": Node(
            async_task=apply_reloc_coord_filter.validate()
            .set_task_instance_id("filter_patrol_events")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("fetch_patrol_events"),
                "roi_gdf": None,
                "roi_name": None,
            }
            | (params_dict.get("filter_patrol_events") or {}),
            method="call",
        ),
        "split_patrol_traj_groups": Node(
            async_task=split_groups.validate()
            .set_task_instance_id("split_patrol_traj_groups")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("traj_colormap"),
                "groupers": DependsOn("groupers"),
            }
            | (params_dict.get("split_patrol_traj_groups") or {}),
            method="call",
        ),
        "split_pe_groups": Node(
            async_task=split_groups.validate()
            .set_task_instance_id("split_pe_groups")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("pe_colormap"),
                "groupers": DependsOn("groupers"),
            }
            | (params_dict.get("split_pe_groups") or {}),
            method="call",
        ),
        "persist_traj_gpkg": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_traj_gpkg")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("patrol_traj"),
                "filename": "patrol_trajectories",
                "filetype": "gpkg",
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            }
            | (params_dict.get("persist_traj_gpkg") or {}),
            method="call",
        ),
        "persist_traj_parquet": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_traj_parquet")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("patrol_traj"),
                "filename": "patrol_trajectories",
                "filetype": "geoparquet",
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            }
            | (params_dict.get("persist_traj_parquet") or {}),
            method="call",
        ),
        "persist_events_gpkg": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_events_gpkg")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("filter_patrol_events"),
                "filename": "patrol_events",
                "filetype": "gpkg",
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            }
            | (params_dict.get("persist_events_gpkg") or {}),
            method="call",
        ),
        "persist_events_parquet": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_events_parquet")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("filter_patrol_events"),
                "filename": "patrol_events",
                "filetype": "geoparquet",
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            }
            | (params_dict.get("persist_events_parquet") or {}),
            method="call",
        ),
        "base_map_defs": Node(
            async_task=set_base_maps.validate()
            .set_task_instance_id("base_map_defs")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("base_map_defs") or {}),
            method="call",
        ),
        "patrol_events_map_layers": Node(
            async_task=create_point_layer.validate()
            .set_task_instance_id("patrol_events_map_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "fill_color_column": "event_type_colormap",
                },
                "legend": None,
                "tooltip_columns": [
                    "patrol_serial_number",
                    "event_type",
                    "time",
                ],
            }
            | (params_dict.get("patrol_events_map_layers") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["geodataframe"],
                "argvalues": DependsOn("split_pe_groups"),
            },
        ),
        "patrol_traj_map_layers": Node(
            async_task=create_polyline_layer.validate()
            .set_task_instance_id("patrol_traj_map_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "get_width": 3,
                    "width_units": "pixels",
                    "color_column": "patrol_traj_colormap",
                },
                "tooltip_columns": [
                    "patrol_serial_number",
                    "patrol_type",
                ],
            }
            | (params_dict.get("patrol_traj_map_layers") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["geodataframe"],
                "argvalues": DependsOn("split_patrol_traj_groups"),
            },
        ),
        "combined_traj_and_pe_map_layers": Node(
            async_task=groupbykey.validate()
            .set_task_instance_id("combined_traj_and_pe_map_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    all_keyed_iterables_are_skips,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "iterables": [
                    DependsOn("patrol_traj_map_layers"),
                    DependsOn("patrol_events_map_layers"),
                ],
            }
            | (params_dict.get("combined_traj_and_pe_map_layers") or {}),
            method="call",
        ),
        "traj_patrol_events_ecomap": Node(
            async_task=draw_ecomap.validate()
            .set_task_instance_id("traj_patrol_events_ecomap")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "tile_layers": DependsOn("base_map_defs"),
                "static": False,
                "max_zoom": 20,
            }
            | (params_dict.get("traj_patrol_events_ecomap") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["geo_layers"],
                "argvalues": DependsOn("combined_traj_and_pe_map_layers"),
            },
        ),
        "traj_pe_ecomap_html_urls": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("traj_pe_ecomap_html_urls")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            }
            | (params_dict.get("traj_pe_ecomap_html_urls") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["text"],
                "argvalues": DependsOn("traj_patrol_events_ecomap"),
            },
        ),
        "traj_pe_map_widgets_single_views": Node(
            async_task=create_map_widget_single_view.validate()
            .set_task_instance_id("traj_pe_map_widgets_single_views")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "title": "Combined Patrol Events and Trajectories",
            }
            | (params_dict.get("traj_pe_map_widgets_single_views") or {}),
            method="map",
            kwargs={
                "argnames": ["view", "data"],
                "argvalues": DependsOn("traj_pe_ecomap_html_urls"),
            },
        ),
        "traj_pe_grouped_map_widget": Node(
            async_task=merge_widget_views.validate()
            .set_task_instance_id("traj_pe_grouped_map_widget")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "widgets": DependsOn("traj_pe_map_widgets_single_views"),
            }
            | (params_dict.get("traj_pe_grouped_map_widget") or {}),
            method="call",
        ),
        "patrol_dashboard": Node(
            async_task=gather_dashboard.validate()
            .set_task_instance_id("patrol_dashboard")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "details": DependsOn("workflow_details"),
                "widgets": [
                    DependsOn("traj_pe_grouped_map_widget"),
                ],
                "groupers": DependsOn("groupers"),
                "time_range": DependsOn("time_range"),
            }
            | (params_dict.get("patrol_dashboard") or {}),
            method="call",
        ),
    }
    graph = Graph(dependencies=dependencies, nodes=nodes)
    results = graph.execute()
    return results
